{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dszigeti\\\\Desktop\\\\py_workspace\\\\20190705\\\\20190705_Load_Forecasting'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of data\n",
    "file = '../data/tacoma.csv'\n",
    "\n",
    "data = pd.read_csv(file)\n",
    "data = pd.melt(data, id_vars=['date', 'high', 'low', 'tdelta'])\n",
    "data.columns = ['date', 'high', 'low', 'tdelta', 'time', 'load']\n",
    "data['date'] = data['date'].astype(str) + ' ' + data['time'].astype(str)\n",
    "data = data.drop('time', axis=1)\n",
    "\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "data.sort_values(by='date', inplace = True)\n",
    "\n",
    "data['date']\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "# time of day\n",
    "data['hour'] = data.index.hour\n",
    "\n",
    "# isoweek number\n",
    "data['dates'] = data.index.date\n",
    "data['iso_week'] = data.dates.apply(lambda x: x.isocalendar()[1])\n",
    "data.drop('dates', axis=1, inplace=True)\n",
    "\n",
    "# 0 = monday, 6 = sunday\n",
    "data['dayofweek'] = data.index.dayofweek\n",
    "#dropna\n",
    "data.dropna(inplace=True)\n",
    "data['temp_avg'] = data[['high', 'low']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add daytype, dayofyear, logload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values for daytype\n",
    "conditions = [\n",
    "    # non workday\n",
    "    (data['dayofweek'].astype(float) == 5),\n",
    "    (data['dayofweek'].astype(float) == 6),\n",
    "    \n",
    "    # day before non workday\n",
    "    (data['dayofweek'].astype(float) == (4)),\n",
    "    \n",
    "    # day after non workday\n",
    "    (data['dayofweek'].astype(float) == (0))]\n",
    "\n",
    "choices = [0, 0, 1, 2]\n",
    "data['day_type'] = np.select(conditions, choices, default='-1')\n",
    "\n",
    "# add columns for dayofyear and logload\n",
    "data['dayofyear'] = data.index.dayofyear\n",
    "data['logload'] = np.log(data.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to file\n",
    "data.to_csv('pydata.csv', index='date', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train/test split\n",
    "* in the future, this will become a function/loop that will do kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "# only iso week 53 is 2016\n",
    "train = data['2013':'2017']\n",
    "\n",
    "#, data['2014-01'], data['2015-01'], data['2016-01'],data['2017-01']\n",
    "test = data['2018']\n",
    "train_load = train.load.to_frame()\n",
    "test_load = test.load.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>tdelta</th>\n",
       "      <th>load</th>\n",
       "      <th>hour</th>\n",
       "      <th>iso_week</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>day_type</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>logload</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:00:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.272877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 01:00:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.251904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 02:00:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 03:00:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.198479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 04:00:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.190315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     high   low  tdelta   load  hour  iso_week  dayofweek  \\\n",
       "date                                                                        \n",
       "2006-01-01 00:00:00  57.0  44.0    13.0  530.0     0        52          6   \n",
       "2006-01-01 01:00:00  57.0  44.0    13.0  519.0     1        52          6   \n",
       "2006-01-01 02:00:00  57.0  44.0    13.0  502.0     2        52          6   \n",
       "2006-01-01 03:00:00  57.0  44.0    13.0  492.0     3        52          6   \n",
       "2006-01-01 04:00:00  57.0  44.0    13.0  488.0     4        52          6   \n",
       "\n",
       "                     temp_avg day_type  dayofyear   logload  \n",
       "date                                                         \n",
       "2006-01-01 00:00:00      50.5        0          1  6.272877  \n",
       "2006-01-01 01:00:00      50.5        0          1  6.251904  \n",
       "2006-01-01 02:00:00      50.5        0          1  6.218600  \n",
       "2006-01-01 03:00:00      50.5        0          1  6.198479  \n",
       "2006-01-01 04:00:00      50.5        0          1  6.190315  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Make Samples data prep\n",
    "* max load past 24 hrs\n",
    "* min load past 24 hrs\n",
    "* avg load past 7 days\n",
    "* high temp past 24 hrs\n",
    "* low temp past 24 hrs\n",
    "* avg temp (??) past 7 days\n",
    "    * is it sufficient to just do high/low average from past days?\n",
    "* day of week\n",
    "* holiday effect\n",
    "* day of year\n",
    "​\n",
    "​\n",
    "## to do later\n",
    "* load for same time past two days (delta?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rn this doesn't do anything\n",
    "def make_samples(df, freq, periods, fun):\n",
    "    \n",
    "    # index of first time:\n",
    "    start_time = df.index.min()\n",
    "    \n",
    "    sample_idx = pd.date_range(start=start_time, freq=freq, periods=periods)\n",
    "    output_idx = pd.date_range(start=sample_idx.max(), end=df.index.max(),\n",
    "                              freq=freq)\n",
    "    output = pd.DataFrame(columns=['load'], index=output_idx)\n",
    "    \n",
    "    \n",
    "    output = output.apply(lambda x: x, axis=1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples: list of data and associated index\n",
    "def get_value(d, s, fun):\n",
    "    value = 0\n",
    "    \n",
    "    if (fun == 'max'):\n",
    "        value = d.loc[s].max()\n",
    "        \n",
    "    elif (fun == 'min'):\n",
    "        value = d.loc[s].min()\n",
    "\n",
    "    elif (fun == 'avg'):\n",
    "        value = d.loc[s].mean()\n",
    "    else:\n",
    "        value = 99999999999999999\n",
    "        \n",
    "    return value\n",
    "\n",
    "# takes as input parameters, spits out a dataframe with the requested data\n",
    "def make_samples(df, freq, periods, fun):\n",
    "    \n",
    "    # first sample's index\n",
    "    start_time = df.index.min()\n",
    "    \n",
    "    sample_idx = pd.date_range(start=start_time, freq=freq, periods=periods)\n",
    "    output_idx = pd.date_range(start=sample_idx.max(), end=df.index.max(), freq=freq)\n",
    "    output = pd.DataFrame(columns=['load'], index=output_idx)\n",
    "                          \n",
    "    for i in output_idx:\n",
    "    \n",
    "        # try to find samples in original df, if not, skip?\n",
    "        try:\n",
    "            output.loc[i] = get_value(df, sample_idx, fun)\n",
    "            \n",
    "        # if any of the sample_idx do not exist in df, skip and calculate next\n",
    "        # this leaves the value as NaN in output\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # iterate time delta by one freq unit                  \n",
    "        start_time = start_time + pd.Timedelta(1, freq)\n",
    "        \n",
    "        #update sample_idx\n",
    "        sample_idx = pd.date_range(start=start_time, freq=freq, periods=periods)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dszigeti\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n",
      "C:\\Users\\dszigeti\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# max temp in 24 hours\n",
    "\n",
    "train_temp_high = make_samples(train.high, 'H', 5, 'max')\n",
    "train_temp_low = make_samples(train.low, 'H', 5, 'min')\n",
    "train_temp_avg = make_samples(train.temp_avg, 'H', 24, 'avg')\n",
    "with plt.xkcd():\n",
    "#    plt.scatter(train_temp_high, np.log(train.load[train_temp_high.index]), facecolor='None', edgecolor='xkcd:purple')\n",
    " #   plt.scatter(train_temp_low, np.log(train.load[train_temp_low.index]), facecolor='None', edgecolor='xkcd:pink')\n",
    "    plt.scatter(train_temp_avg, np.log(train.load[train_temp_avg.index]), facecolor='None', edgecolor='xkcd:blue')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp_high = make_samples(test.high, 'H', 5, 'max')\n",
    "test_temp_low = make_samples(test.low, 'H', 5, 'min')\n",
    "test_temp_avg = make_samples(test.temp_avg, 'H', 24, 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calendar Effects\n",
    "* day of week\n",
    "* type of day\n",
    "* new year's eve\n",
    "* christmas\n",
    "* smooth function (estimated with cubic regression spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load_max = make_samples(train.load, 'H', 6, 'max')\n",
    "train_load_min = make_samples(train.load, 'H', 6, 'min')\n",
    "train_load_avg = make_samples(train.load, 'H', 6, 'avg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "#    plt.scatter(train_temp_high, np.log(train.load[train_temp_high.index]), facecolor='None', edgecolor='xkcd:purple')\n",
    " #   plt.scatter(train_temp_low, np.log(train.load[train_temp_low.index]), facecolor='None', edgecolor='xkcd:pink')\n",
    "    plt.plot(train_load_max.index, train_load_max, color='xkcd:blue')\n",
    "    plt.plot(train_load_avg.index, train_load_avg, color='xkcd:purple')\n",
    "    plt.plot(train_load_min.index, train_load_min, color='xkcd:pink')\n",
    "    plt.legend(['max', 'avg', 'min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load_max = make_samples(test.load, 'H', 24, 'max')\n",
    "test_load_min = make_samples(test.load, 'H', 24, 'min')\n",
    "test_load_avg = make_samples(test.load, 'H', 24, 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample training data\n",
    "\n",
    "# data: data\n",
    "# name of data column\n",
    "# bucket = Day, month?\n",
    "def prep_data(data, name, bucket):\n",
    "    \n",
    "    # down sample data\n",
    "    data_new = data.resample('%s' %(bucket)).mean()\n",
    "    data_new.columns = ['%s' %(name)]\n",
    "    \n",
    "    # make time buckets for new index\n",
    "    data_new['date_delta'] = (data_new.index - data_new.index.min())/ np.timedelta64(1, '%s' %(bucket))\n",
    "    \n",
    "    X_train = data_new['date_delta']\n",
    "    y_train = data_new['%s' %(name)]\n",
    "    \n",
    "    # set up cubic spline\n",
    "    from scipy.interpolate import UnivariateSpline\n",
    "    spline = UnivariateSpline(X_train, y_train, k=3, s=5)\n",
    "    \n",
    "    return spline\n",
    "\n",
    "# downsample test data and predict with spline\n",
    "def predict_spline(data, name, bucket, spline):\n",
    "    # downsample\n",
    "    from scipy import interpolate\n",
    "    data_new = data.resample('%s' %(bucket)).mean().to_frame()\n",
    "    data_new.columns = ['%s' %(name)]\n",
    "    \n",
    "    \n",
    "    data_new['date_delta'] = (data_new.index - data_new.index.min()) / np.timedelta64(1, '%s' %(bucket))\n",
    "    data_new.columns = ['%s' %(name), 'date_delta']\n",
    "    X_test = data_new['date_delta']\n",
    "    y_test = data_new['%s' %(name)]\n",
    "    prediction = spline(X_test)\n",
    "\n",
    "    return y_test, prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_daytype = train.day_type\n",
    "test_daytype = test.day_type\n",
    "train['dayofyear'] = train.index.dayofyear\n",
    "test['dayofyear'] = test.index.dayofyear\n",
    "train_dayofyear = train.dayofyear\n",
    "test_dayofyear = test.dayofyear\n",
    "train_log_load = np.log(train.load)\n",
    "test_log_load = np.log(test.load)\n",
    "\n",
    "train_dayofyear = train.dayofyear\n",
    "test_dayofyear = test.dayofyear\n",
    "train_log_load = np.log(train.load)\n",
    "test_log_load = np.log(test.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index of train_processed to same as train\n",
    "train_processed = pd.DataFrame(index=train.index)\n",
    "\n",
    "#train_processed['tdelta'] = train.tdelta\n",
    "train_processed['high'] = train_temp_high\n",
    "train_processed['avg'] = train_temp_avg\n",
    "train_processed['low'] = train_temp_low\n",
    "train_processed['load_max'] = train_load_max\n",
    "train_processed['load_avg'] = train_load_avg\n",
    "train_processed['load_min'] = train_load_min\n",
    "train_processed['iso_week'] = train.iso_week\n",
    "train_processed['dayofweek'] = train.dayofweek\n",
    "train_processed['hour'] = train.hour\n",
    "train_processed['load_true'] = train.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed['high_true'] = train.high\n",
    "train_processed['low_true'] = train.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values for daytype\n",
    "conditions = [\n",
    "    # non workday\n",
    "    (train_processed['dayofweek'].astype(float) == 5),\n",
    "    (train_processed['dayofweek'].astype(float) == 6),\n",
    "    \n",
    "    # day before non workday\n",
    "    (train_processed['dayofweek'].astype(float) == (4)),\n",
    "    \n",
    "    # day after non workday\n",
    "    (train_processed['dayofweek'].astype(float) == (0))]\n",
    "\n",
    "choices = [0, 0, 1, 2]\n",
    "train_processed['day_type'] = np.select(conditions, choices, default='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill na\n",
    "train_processed.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! rewrite this if it's faster to find intersection than to loc\n",
    "# make dataset for weeks\n",
    "def make_dataset(data, week_id, day_id, hour_id):\n",
    "  \n",
    "    if week_id == 1:\n",
    "        last_week = data.loc[(data.iso_week == 52)\n",
    "                     & (data.dayofweek == day_id)\n",
    "                     & (data.hour == hour_id)]\n",
    "    else:\n",
    "        last_week = data.loc[(data.iso_week == week_id - 1)\n",
    "                     & (data.dayofweek == day_id)\n",
    "                     & (data.hour == hour_id)]\n",
    "\n",
    "    this_week = data.loc[(data.iso_week == week_id)\n",
    "                     & (data.dayofweek == day_id)\n",
    "                     & (data.hour == hour_id)]\n",
    "    \n",
    "    \n",
    "    next_week = data.loc[(data.iso_week == week_id + 1)\n",
    "                     & (data.dayofweek == day_id)\n",
    "                     & (data.hour == hour_id)]\n",
    "    \n",
    "    week = [last_week, this_week, next_week]\n",
    "    week = pd.concat(week)\n",
    "    return week\n",
    "\n",
    "# take training data and find a line\n",
    "# returns intercept and coefficient\n",
    "def fit_model(X_train, y_train):\n",
    "    model = linear_model.LinearRegression()\n",
    "    results = model.fit(X_train, y_train)\n",
    "    intercept, coef = results.intercept_, results.coef_\n",
    "    return intercept, coef\n",
    "\n",
    "int_list = list()\n",
    "coef_list = list()\n",
    "idx_list = list()\n",
    "\n",
    "for wk in range(1, 53, +1):\n",
    "  for day in range(0, 7, +1):\n",
    "    for hour in range(0, 24, +1):\n",
    "        train_subset = make_dataset(train_processed, wk, day, hour).dropna()\n",
    "        # get the subset of data to be tested for model\n",
    "        \n",
    "        # split x/y data\n",
    "        y_train, X_train = train_subset.load_true, train_subset.drop(['load_true'], axis=1)\n",
    "\n",
    "        \n",
    "        intercept, coef = fit_model(X_train, y_train)\n",
    "        idx = [wk, day, hour]\n",
    "        idx_list.append(idx)\n",
    "        int_list.append(intercept)\n",
    "        coef_list.append(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test data for testing\n",
    "# set index of train_processed to same as train\n",
    "test_processed = pd.DataFrame(index=test.index)\n",
    "\n",
    "#test_processed['tdelta'] = test.tdelta\n",
    "test_processed['high'] = test_temp_high\n",
    "test_processed['avg'] = test_temp_avg\n",
    "test_processed['low'] = test_temp_low\n",
    "test_processed['load_max'] = test_load_max\n",
    "test_processed['load_avg'] = test_load_avg\n",
    "test_processed['load_min'] = test_load_min\n",
    "test_processed['iso_week'] = test.iso_week\n",
    "test_processed['dayofweek'] = test.dayofweek\n",
    "test_processed['hour'] = test.hour\n",
    "test_processed['load_true'] = test.load\n",
    "test_processed['high_true'] = test.high\n",
    "test_processed['low_true'] = test.low\n",
    "\n",
    "conditions = [\n",
    "    # non workday\n",
    "    (test_processed['dayofweek'].astype(float) == 5),\n",
    "    (test_processed['dayofweek'].astype(float) == 6),\n",
    "    \n",
    "    # day before non workday\n",
    "    (test_processed['dayofweek'].astype(float) == (4)),\n",
    "    \n",
    "    # day after non workday\n",
    "    (test_processed['dayofweek'].astype(float) == (0))]\n",
    "\n",
    "\n",
    "test_processed['day_type'] = np.select(conditions, choices, default='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_processed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, X_test = test_processed.load_true, test_processed.drop(['load_true'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model! ヽ(o＾▽＾o)ノ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn output into dataframes and combine\n",
    "intercept = pd.DataFrame({'intercept':int_list})\n",
    "coefficients = pd.DataFrame(coef_list, columns=[#'xtdelta', \n",
    "                                               'xhigh',\n",
    "                                               'xavg',\n",
    "                                               'xlow',\n",
    "                                               'xload_max',\n",
    "                                               'xload_avg',\n",
    "                                               'xload_min',\n",
    "                                               'xiso_week',\n",
    "                                               'xdayofweek',\n",
    "                                               'xhour',\n",
    "                                               'xday_type',\n",
    "                                               'xhigh_true',\n",
    "                                               'xlow_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.DataFrame(idx_list, columns=['iso_week', 'dayofweek', 'hour'])\n",
    "final_model = pd.DataFrame.join(intercept, coefficients, how='outer')\n",
    "final_model = pd.DataFrame.join(idx, final_model, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.drop(['xdayofweek', 'xhour','xday_type'], axis=1)\n",
    "X_input = X_test[24:]\n",
    "print(len(final_model))\n",
    "print(len(X_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame.merge(final_model, X_input, on=['iso_week', 'hour', 'dayofweek'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction!\n",
    "prediction = (#X_input.tdelta.values * coef.xtdelta.values\n",
    "          X_input.high.values * coef.xhigh.values\n",
    "        + X_input.avg.values * coef.xavg.values\n",
    "        + X_input.low.values * coef.xlow.values \n",
    "        + X_input.load_max.values * coef.xload_max.values\n",
    "        + X_input.load_avg.values * coef.xload_avg.values\n",
    "        + X_input.load_min.values * coef.xload_min.values\n",
    "        + X_input.high_true.values * coef.xhigh_true.values\n",
    "        + X_input.low_true.values * coef.xlow_true.values\n",
    "        + coef.intercept.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import figure\n",
    "\n",
    "rcParams['figure.figsize'] = 30, 10\n",
    "# rotate and align the tick labels so they look better\n",
    "\n",
    "start = 0\n",
    "end = 500\n",
    "\n",
    "\n",
    "plt.plot(prediction[start:end])\n",
    "plt.plot(y_test[start:end].values)\n",
    "\n",
    "\n",
    "plt.plot(x[start:end])\n",
    "\n",
    "plt.legend(['prediction', 'actual','nona'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# MAPE function\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    if y_pred.isnull() == False:\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    else: return\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "  \n",
    "RMSE = sqrt(mean_squared_error(y_test[start:end], prediction[start:end]))\n",
    "MAPE = mean_absolute_percentage_error(y_test[start:end], prediction[start:end])\n",
    "\n",
    "print('RMSE: [{}]'.format(RMSE))\n",
    "print('MAPE: [{}]'.format(MAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
